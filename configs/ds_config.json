
// 使用lion优化器
"optimizer": {
    "type": "Lion",
    "params": {
      "lr": 2e-6,
      "betas": [
        0.9,
        0.999
      ],
      "use_triton": true,
      "weight_decay": 2e-3
    }
},

"scheduler": {
    "type": "WarmupDecayLR",
    "params": {
        "warmup_num_steps": 200,
        "total_num_steps": -1,
        "warmup_min_lr": 0,
        "warmup_max_lr": -1
    }
},
// offload的，必须使用zero
"zero_allow_untested_optimizer": true,
"zero_force_ds_cpu_optimizer": false, 
"zero_optimization": {
    "stage": 1,
    "offload_param": {
        "device": "cpu",
        "pin_memory": true
    },
    "offload_optimizer": {
        "device": "cpu",
        "pin_memory": true
    }
},

// 这个应该是qat的东西  
"compression_training": {
    "activation_quantization": {
        "shared_parameters":{
            "enabled": true,
            "quantization_type": "symmetric",
            "range_calibration": "dynamic",
            "schedule_offset": 20 // 从哪个iter开始加上这个，0表示从一开始就加上
        },
        "different_groups":{
          "aq1": {
            "params": {
              "bits": 8
            },
            "modules": ["self_attention"," mlp"]
          }
        }
    },
    "weight_quantization": {
        "shared_parameters":{
            "enabled": true,
            "quantizer_kernel": false,
            "schedule_offset": 20, // 从哪个iter开始加上这个，0表示从一开始就加上
            "quantize_groups": 64,
            "quantize_verbose": false,
            "quantization_type": "symmetric",
            "quantize_weight_in_forward": false,
            "rounding": "nearest",
            "fp16_mixed_quantize":{
                "enabled": false,
                "quantize_change_ratio": 1
            }
        },
        "different_groups":{
            "wq1": {
                "params": {
                    "start_bits": 8, 
                    "target_bits": 8,
                    "quantization_period": 0
                },
            "modules": ["self_attention"," mlp"]
            }
        }
    }
}
